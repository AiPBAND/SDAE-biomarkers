{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised training of the encoder layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:31.785403Z",
     "iopub.status.busy": "2020-08-07T12:55:31.785013Z",
     "iopub.status.idle": "2020-08-07T12:55:35.280541Z",
     "shell.execute_reply": "2020-08-07T12:55:35.279253Z",
     "shell.execute_reply.started": "2020-08-07T12:55:31.785372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0-dlenv\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from models import Autoencoder, EncoderStack\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import normalize\n",
    "import dataset\n",
    "import neptune\n",
    "import neptune_tensorboard as neptune_tb\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set experiment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:35.282684Z",
     "iopub.status.busy": "2020-08-07T12:55:35.282284Z",
     "iopub.status.idle": "2020-08-07T12:55:35.288829Z",
     "shell.execute_reply": "2020-08-07T12:55:35.287591Z",
     "shell.execute_reply.started": "2020-08-07T12:55:35.282648Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"N_NODES\": [2000, 1000, 500],\n",
    "    \"DROPOUT\": [0.1],\n",
    "    \"BATCH_SIZE\": 15,\n",
    "    \"EPOCHS\": 150,\n",
    "    \"TEST_RATIO\": 0.20,\n",
    "    \"DATA_BUCKET\": \"sdae-geo\",\n",
    "    \"DATA_OBJECT\": \"GEO_data_batch_corr_final.csv\",\n",
    "    \"DATA_LABELS\": \" GBM_class.csv\",\n",
    "    \"VERBOSITY\": 2,\n",
    "    \"LOG_DIR\": \"./log_dir\",\n",
    "    \"PATIENCE\":5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Netptune and Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:35.291565Z",
     "iopub.status.busy": "2020-08-07T12:55:35.291182Z",
     "iopub.status.idle": "2020-08-07T12:55:45.125012Z",
     "shell.execute_reply": "2020-08-07T12:55:45.123780Z",
     "shell.execute_reply.started": "2020-08-07T12:55:35.291533Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NVMLError: NVML Shared Library Not Found - GPU usage metrics may not be reported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/AiPBBAND/SDAE/e/SAN-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "project directory: ./log_dir/SAN-5\n"
     ]
    }
   ],
   "source": [
    "os.environ['NEPTUNE_API_TOKEN']=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiYjNiYmZhYjEtNzc3ZS00Y2NhLWI5NTgtYWU0MmQyMWJhM2I0In0=\"\n",
    "os.environ['NEPTUNE_PROJECT']='AiPBBAND/SDAE'\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\"ecd86e96-4da7-44e3-9a17-43da2dfcae35\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"constrained-SDAE/sdae.ipynb\"\n",
    "\n",
    "neptune.init(os.environ['NEPTUNE_PROJECT'], api_token=os.environ['NEPTUNE_API_TOKEN'])\n",
    "\n",
    "logger = logging.getLogger(\"SDAE\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "experiment = neptune.create_experiment(name='configuration', params=config, \n",
    "    logger=logger, upload_source_files=[\"*.py\"])\n",
    "\n",
    "os.environ['EXP_DIR'] = os.path.join(config[\"LOG_DIR\"], experiment.id)\n",
    "os.mkdir(os.environ['EXP_DIR'])\n",
    "\n",
    "logger.info(\"project directory: {}\".format(os.environ['EXP_DIR']))\n",
    "!neptune tensorboard ${EXP_DIR} --project ${NEPTUNE_PROJECT}\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start tensorboard server\n",
    "Tensorboard by running the following command in a terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:45.127031Z",
     "iopub.status.busy": "2020-08-07T12:55:45.126695Z",
     "iopub.status.idle": "2020-08-07T12:55:45.132440Z",
     "shell.execute_reply": "2020-08-07T12:55:45.131400Z",
     "shell.execute_reply.started": "2020-08-07T12:55:45.126997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir ./log_dir/SAN-5 --bind_all\n"
     ]
    }
   ],
   "source": [
    "print(\"tensorboard --logdir {} --bind_all\".format(os.environ['EXP_DIR']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T00:26:47.747982Z",
     "iopub.status.busy": "2020-08-07T00:26:47.747592Z",
     "iopub.status.idle": "2020-08-07T00:26:47.754814Z",
     "shell.execute_reply": "2020-08-07T00:26:47.753548Z",
     "shell.execute_reply.started": "2020-08-07T00:26:47.747952Z"
    }
   },
   "source": [
    "**Tensorboard cannot server over HTTPS, use external HTTP url: http://34.77.45.86:6006/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Google Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:45.134542Z",
     "iopub.status.busy": "2020-08-07T12:55:45.134014Z",
     "iopub.status.idle": "2020-08-07T12:55:48.604350Z",
     "shell.execute_reply": "2020-08-07T12:55:48.602822Z",
     "shell.execute_reply.started": "2020-08-07T12:55:45.134483Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Downloading data files from GS storage.\n",
      "File GEO_data_batch_corr_final.csv downloaded to ./log_dir/SAN-5/GEO_data_batch_corr_final.csv.\n",
      "Loaded 954 samples with 6785 features.\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataset.load_gs_data(config['DATA_BUCKET'], config['DATA_OBJECT'], os.environ['EXP_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data feature-wize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:48.606395Z",
     "iopub.status.busy": "2020-08-07T12:55:48.605999Z",
     "iopub.status.idle": "2020-08-07T12:55:48.701526Z",
     "shell.execute_reply": "2020-08-07T12:55:48.700243Z",
     "shell.execute_reply.started": "2020-08-07T12:55:48.606360Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dataframe.values\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:48.703308Z",
     "iopub.status.busy": "2020-08-07T12:55:48.702994Z",
     "iopub.status.idle": "2020-08-07T12:55:49.585614Z",
     "shell.execute_reply": "2020-08-07T12:55:49.584622Z",
     "shell.execute_reply.started": "2020-08-07T12:55:48.703279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20% of samples for training: 763 training, 191 testing.\n"
     ]
    }
   ],
   "source": [
    "rs = ShuffleSplit(n_splits=1, test_size=config['TEST_RATIO'], random_state=0)\n",
    "split_itterator = rs.split(data)\n",
    "i_train, i_test = next(split_itterator)\n",
    "train_path = os.path.join(os.environ['EXP_DIR'], \"train_indices.npy\")\n",
    "test_path = os.path.join(os.environ['EXP_DIR'], \"test_indices.npy\")\n",
    "np.save(train_path, i_train)\n",
    "np.save(test_path, i_test)\n",
    "neptune.log_artifact(train_path)\n",
    "neptune.log_artifact(test_path)\n",
    "\n",
    "x_train, x_test = data[i_train], data[i_test]\n",
    "\n",
    "logger.info(\"{}% of samples for training: {} training, {} testing.\".format(int(config['TEST_RATIO']*100), len(i_train), len(i_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T03:12:17.561113Z",
     "iopub.status.busy": "2020-07-27T03:12:17.560466Z",
     "iopub.status.idle": "2020-07-27T03:12:17.565053Z",
     "shell.execute_reply": "2020-07-27T03:12:17.564431Z",
     "shell.execute_reply.started": "2020-07-27T03:12:17.561079Z"
    }
   },
   "source": [
    "# Train encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T12:55:49.587684Z",
     "iopub.status.busy": "2020-08-07T12:55:49.587398Z",
     "iopub.status.idle": "2020-08-07T13:08:06.370940Z",
     "shell.execute_reply": "2020-08-07T13:08:06.369695Z",
     "shell.execute_reply.started": "2020-08-07T12:55:49.587654Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting training for 3 encoder layers.\n",
      "Training layer 0 with 2000 hidden nodes..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "51/51 [==============================] - 12s 228ms/step - loss: 0.1745 - val_loss: 0.0683\n",
      "Epoch 2/150\n",
      "51/51 [==============================] - 11s 219ms/step - loss: 0.0202 - val_loss: 0.0055\n",
      "Epoch 3/150\n",
      "51/51 [==============================] - 11s 220ms/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 4/150\n",
      "51/51 [==============================] - 11s 216ms/step - loss: 0.0011 - val_loss: 6.8450e-04\n",
      "Epoch 5/150\n",
      "51/51 [==============================] - 11s 225ms/step - loss: 4.6739e-04 - val_loss: 3.5521e-04\n",
      "Epoch 6/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 2.4919e-04 - val_loss: 2.0065e-04\n",
      "Epoch 7/150\n",
      "51/51 [==============================] - 11s 219ms/step - loss: 1.4786e-04 - val_loss: 1.1501e-04\n",
      "Epoch 8/150\n",
      "51/51 [==============================] - 11s 217ms/step - loss: 9.2820e-05 - val_loss: 7.1589e-05\n",
      "Epoch 9/150\n",
      "51/51 [==============================] - 11s 212ms/step - loss: 6.4068e-05 - val_loss: 4.7529e-05\n",
      "Epoch 10/150\n",
      "51/51 [==============================] - 12s 226ms/step - loss: 4.5644e-05 - val_loss: 3.5816e-05\n",
      "Epoch 11/150\n",
      "51/51 [==============================] - 11s 221ms/step - loss: 3.5517e-05 - val_loss: 3.1576e-05\n",
      "Epoch 12/150\n",
      "51/51 [==============================] - 11s 221ms/step - loss: 2.7652e-05 - val_loss: 2.6395e-05\n",
      "Epoch 13/150\n",
      "51/51 [==============================] - 11s 224ms/step - loss: 2.2832e-05 - val_loss: 2.0733e-05\n",
      "Epoch 14/150\n",
      "51/51 [==============================] - 11s 216ms/step - loss: 1.9379e-05 - val_loss: 1.9147e-05\n",
      "Epoch 15/150\n",
      "51/51 [==============================] - 11s 222ms/step - loss: 1.6427e-05 - val_loss: 1.3387e-05\n",
      "Epoch 16/150\n",
      "51/51 [==============================] - 11s 223ms/step - loss: 1.4530e-05 - val_loss: 1.4396e-05\n",
      "Epoch 17/150\n",
      "51/51 [==============================] - 11s 219ms/step - loss: 1.3240e-05 - val_loss: 1.2803e-05\n",
      "Epoch 18/150\n",
      "51/51 [==============================] - 11s 220ms/step - loss: 1.1667e-05 - val_loss: 1.0111e-05\n",
      "Epoch 19/150\n",
      "51/51 [==============================] - 11s 220ms/step - loss: 1.0583e-05 - val_loss: 1.1329e-05\n",
      "Epoch 20/150\n",
      "51/51 [==============================] - 11s 225ms/step - loss: 9.7272e-06 - val_loss: 9.5517e-06\n",
      "Epoch 21/150\n",
      "51/51 [==============================] - 11s 217ms/step - loss: 8.9935e-06 - val_loss: 8.4745e-06\n",
      "Epoch 22/150\n",
      "51/51 [==============================] - 13s 249ms/step - loss: 8.4479e-06 - val_loss: 7.6243e-06\n",
      "Epoch 23/150\n",
      "51/51 [==============================] - 12s 228ms/step - loss: 8.1156e-06 - val_loss: 7.7200e-06\n",
      "Epoch 24/150\n",
      "51/51 [==============================] - 11s 220ms/step - loss: 7.4117e-06 - val_loss: 7.0714e-06\n",
      "Epoch 25/150\n",
      "51/51 [==============================] - 11s 222ms/step - loss: 7.1036e-06 - val_loss: 7.2223e-06\n",
      "Epoch 26/150\n",
      "51/51 [==============================] - 11s 219ms/step - loss: 6.7556e-06 - val_loss: 6.7695e-06\n",
      "Epoch 27/150\n",
      "51/51 [==============================] - 11s 221ms/step - loss: 6.5275e-06 - val_loss: 5.6909e-06\n",
      "Epoch 28/150\n",
      "51/51 [==============================] - 11s 221ms/step - loss: 6.0498e-06 - val_loss: 5.9265e-06\n",
      "Epoch 29/150\n",
      "51/51 [==============================] - 11s 214ms/step - loss: 5.8745e-06 - val_loss: 6.7564e-06\n",
      "Epoch 30/150\n",
      "51/51 [==============================] - 11s 219ms/step - loss: 5.9690e-06 - val_loss: 5.9481e-06\n",
      "Epoch 31/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 5.4203e-06 - val_loss: 5.1132e-06\n",
      "Epoch 32/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 5.2748e-06 - val_loss: 5.0715e-06\n",
      "Epoch 33/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 5.0891e-06 - val_loss: 5.5270e-06\n",
      "Epoch 34/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 4.9639e-06 - val_loss: 4.4629e-06\n",
      "Epoch 35/150\n",
      "51/51 [==============================] - 11s 222ms/step - loss: 4.7862e-06 - val_loss: 4.4035e-06\n",
      "Epoch 36/150\n",
      "51/51 [==============================] - 11s 223ms/step - loss: 4.5920e-06 - val_loss: 4.4758e-06\n",
      "Epoch 37/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 4.5754e-06 - val_loss: 4.0185e-06\n",
      "Epoch 38/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 4.4559e-06 - val_loss: 4.4152e-06\n",
      "Epoch 39/150\n",
      "51/51 [==============================] - 11s 219ms/step - loss: 4.2310e-06 - val_loss: 4.3571e-06\n",
      "Epoch 40/150\n",
      "51/51 [==============================] - 11s 218ms/step - loss: 4.2148e-06 - val_loss: 4.4301e-06\n",
      "Epoch 41/150\n",
      "51/51 [==============================] - 11s 211ms/step - loss: 4.1770e-06 - val_loss: 5.4406e-06\n",
      "Epoch 42/150\n",
      "51/51 [==============================] - 11s 222ms/step - loss: 4.2110e-06 - val_loss: 4.6070e-06\n",
      "Epoch 00042: early stopping\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./log_dir/SAN-5/autoencoder-2000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trained model saved at: ./log_dir/SAN-5/autoencoder-2000\n",
      "Training losss for layer 0: 4.5784613575960975e-06 \n",
      "Testing loss for layer 0: 4.584167527355021e-06 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./log_dir/SAN-5/encoders/model_0_2000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training layer 1 with 1000 hidden nodes..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0579 - val_loss: 0.0050\n",
      "Epoch 2/150\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 0.0152 - val_loss: 0.0067\n",
      "Epoch 3/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 4/150\n",
      "51/51 [==============================] - 2s 48ms/step - loss: 0.0022 - val_loss: 9.1023e-04\n",
      "Epoch 5/150\n",
      "51/51 [==============================] - 3s 53ms/step - loss: 0.0012 - val_loss: 6.4891e-04\n",
      "Epoch 6/150\n",
      "51/51 [==============================] - 3s 59ms/step - loss: 5.8794e-04 - val_loss: 4.6717e-04\n",
      "Epoch 7/150\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 3.7593e-04 - val_loss: 2.9682e-04\n",
      "Epoch 8/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 2.4743e-04 - val_loss: 2.1919e-04\n",
      "Epoch 9/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 1.7648e-04 - val_loss: 1.6180e-04\n",
      "Epoch 10/150\n",
      "51/51 [==============================] - 2s 40ms/step - loss: 1.3074e-04 - val_loss: 1.3309e-04\n",
      "Epoch 11/150\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 1.0083e-04 - val_loss: 8.8046e-05\n",
      "Epoch 12/150\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 7.9350e-05 - val_loss: 6.6330e-05\n",
      "Epoch 13/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 6.3777e-05 - val_loss: 5.7630e-05\n",
      "Epoch 14/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 5.2014e-05 - val_loss: 5.1849e-05\n",
      "Epoch 15/150\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 4.3300e-05 - val_loss: 3.7202e-05\n",
      "Epoch 16/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 3.6601e-05 - val_loss: 3.0346e-05\n",
      "Epoch 17/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 3.0909e-05 - val_loss: 3.5045e-05\n",
      "Epoch 18/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 2.7299e-05 - val_loss: 3.1005e-05\n",
      "Epoch 19/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 2.3887e-05 - val_loss: 2.0905e-05\n",
      "Epoch 20/150\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 2.0883e-05 - val_loss: 2.2698e-05\n",
      "Epoch 21/150\n",
      "51/51 [==============================] - 2s 47ms/step - loss: 1.8424e-05 - val_loss: 1.9750e-05\n",
      "Epoch 22/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 1.6646e-05 - val_loss: 1.4708e-05\n",
      "Epoch 23/150\n",
      "51/51 [==============================] - 2s 40ms/step - loss: 1.5226e-05 - val_loss: 1.5326e-05\n",
      "Epoch 24/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 1.3630e-05 - val_loss: 1.1021e-05\n",
      "Epoch 25/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 1.2716e-05 - val_loss: 1.1521e-05\n",
      "Epoch 26/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 1.1151e-05 - val_loss: 1.2103e-05\n",
      "Epoch 27/150\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 1.0935e-05 - val_loss: 1.0091e-05\n",
      "Epoch 28/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 9.8893e-06 - val_loss: 1.0988e-05\n",
      "Epoch 29/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 9.2148e-06 - val_loss: 8.5829e-06\n",
      "Epoch 30/150\n",
      "51/51 [==============================] - 2s 46ms/step - loss: 8.7804e-06 - val_loss: 8.8501e-06\n",
      "Epoch 31/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 8.2438e-06 - val_loss: 7.7051e-06\n",
      "Epoch 32/150\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 7.6316e-06 - val_loss: 6.3155e-06\n",
      "Epoch 33/150\n",
      "51/51 [==============================] - 2s 39ms/step - loss: 7.2368e-06 - val_loss: 6.1349e-06\n",
      "Epoch 34/150\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 7.0437e-06 - val_loss: 5.8321e-06\n",
      "Epoch 35/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 6.4735e-06 - val_loss: 5.5179e-06\n",
      "Epoch 36/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 6.3331e-06 - val_loss: 6.3360e-06\n",
      "Epoch 37/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 5.7999e-06 - val_loss: 5.7750e-06\n",
      "Epoch 38/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 5.8580e-06 - val_loss: 6.2295e-06\n",
      "Epoch 39/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 5.2854e-06 - val_loss: 4.8728e-06\n",
      "Epoch 40/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 5.2170e-06 - val_loss: 5.8146e-06\n",
      "Epoch 41/150\n",
      "51/51 [==============================] - 2s 39ms/step - loss: 5.0794e-06 - val_loss: 4.7528e-06\n",
      "Epoch 42/150\n",
      "51/51 [==============================] - 2s 45ms/step - loss: 4.8881e-06 - val_loss: 4.0782e-06\n",
      "Epoch 43/150\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 4.6829e-06 - val_loss: 5.1643e-06\n",
      "Epoch 44/150\n",
      "51/51 [==============================] - 2s 42ms/step - loss: 4.6115e-06 - val_loss: 3.9722e-06\n",
      "Epoch 45/150\n",
      "51/51 [==============================] - 2s 43ms/step - loss: 4.4273e-06 - val_loss: 4.9630e-06\n",
      "Epoch 46/150\n",
      "51/51 [==============================] - 2s 41ms/step - loss: 4.2238e-06 - val_loss: 3.0056e-06\n",
      "Epoch 47/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 4.0399e-06 - val_loss: 4.2865e-06\n",
      "Epoch 48/150\n",
      "51/51 [==============================] - 2s 49ms/step - loss: 4.0606e-06 - val_loss: 3.8984e-06\n",
      "Epoch 49/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 3.9320e-06 - val_loss: 4.3737e-06\n",
      "Epoch 50/150\n",
      "51/51 [==============================] - 2s 44ms/step - loss: 3.8528e-06 - val_loss: 3.3169e-06\n",
      "Epoch 51/150\n",
      "51/51 [==============================] - 2s 38ms/step - loss: 3.6051e-06 - val_loss: 4.2276e-06\n",
      "Epoch 00051: early stopping\n",
      "INFO:tensorflow:Assets written to: ./log_dir/SAN-5/autoencoder-1000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trained model saved at: ./log_dir/SAN-5/autoencoder-1000\n",
      "Training losss for layer 1: 4.147608706261963e-06 \n",
      "Testing loss for layer 1: 4.163621724728728e-06 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./log_dir/SAN-5/encoders/model_1_1000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training layer 2 with 500 hidden nodes..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "51/51 [==============================] - 1s 25ms/step - loss: 0.0174 - val_loss: 0.0130\n",
      "Epoch 2/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.0100 - val_loss: 0.0075\n",
      "Epoch 3/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.0069 - val_loss: 0.0060\n",
      "Epoch 4/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 5/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 6/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 7/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 8/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 0.0012 - val_loss: 8.8582e-04\n",
      "Epoch 9/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 9.1090e-04 - val_loss: 8.2162e-04\n",
      "Epoch 10/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 7.0669e-04 - val_loss: 6.4452e-04\n",
      "Epoch 11/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 5.4001e-04 - val_loss: 4.3009e-04\n",
      "Epoch 12/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 4.1707e-04 - val_loss: 3.3133e-04\n",
      "Epoch 13/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 3.4132e-04 - val_loss: 3.1321e-04\n",
      "Epoch 14/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 2.7556e-04 - val_loss: 2.2443e-04\n",
      "Epoch 15/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 2.1741e-04 - val_loss: 2.2900e-04\n",
      "Epoch 16/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 1.8882e-04 - val_loss: 1.8258e-04\n",
      "Epoch 17/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 1.5516e-04 - val_loss: 1.3327e-04\n",
      "Epoch 18/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 1.3377e-04 - val_loss: 1.3653e-04\n",
      "Epoch 19/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 1.1264e-04 - val_loss: 1.3241e-04\n",
      "Epoch 20/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 9.9736e-05 - val_loss: 8.2914e-05\n",
      "Epoch 21/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 8.6745e-05 - val_loss: 9.9576e-05\n",
      "Epoch 22/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 7.4504e-05 - val_loss: 6.6002e-05\n",
      "Epoch 23/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 6.6587e-05 - val_loss: 4.9644e-05\n",
      "Epoch 24/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 5.9157e-05 - val_loss: 4.8213e-05\n",
      "Epoch 25/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 5.3397e-05 - val_loss: 3.5051e-05\n",
      "Epoch 26/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 4.7451e-05 - val_loss: 4.8341e-05\n",
      "Epoch 27/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 4.2248e-05 - val_loss: 4.9798e-05\n",
      "Epoch 28/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 3.9730e-05 - val_loss: 3.4700e-05\n",
      "Epoch 29/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 3.5763e-05 - val_loss: 3.5989e-05\n",
      "Epoch 30/150\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 3.2255e-05 - val_loss: 3.2320e-05\n",
      "Epoch 31/150\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 2.9183e-05 - val_loss: 3.2847e-05\n",
      "Epoch 32/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 2.7267e-05 - val_loss: 2.7433e-05\n",
      "Epoch 33/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 2.4569e-05 - val_loss: 1.5234e-05\n",
      "Epoch 34/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 2.2435e-05 - val_loss: 1.7723e-05\n",
      "Epoch 35/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 2.1150e-05 - val_loss: 2.3863e-05\n",
      "Epoch 36/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 1.9919e-05 - val_loss: 1.9982e-05\n",
      "Epoch 37/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 1.8141e-05 - val_loss: 1.3895e-05\n",
      "Epoch 38/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 1.6267e-05 - val_loss: 1.8460e-05\n",
      "Epoch 39/150\n",
      "51/51 [==============================] - 1s 24ms/step - loss: 1.6357e-05 - val_loss: 1.3468e-05\n",
      "Epoch 40/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 1.5022e-05 - val_loss: 2.1667e-05\n",
      "Epoch 41/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 1.3695e-05 - val_loss: 1.2785e-05\n",
      "Epoch 42/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 1.2605e-05 - val_loss: 2.0173e-05\n",
      "Epoch 43/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 1.2579e-05 - val_loss: 8.9361e-06\n",
      "Epoch 44/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 1.1374e-05 - val_loss: 1.5456e-05\n",
      "Epoch 45/150\n",
      "51/51 [==============================] - 1s 21ms/step - loss: 1.0863e-05 - val_loss: 1.5413e-05\n",
      "Epoch 46/150\n",
      "51/51 [==============================] - 1s 22ms/step - loss: 1.0182e-05 - val_loss: 1.0117e-05\n",
      "Epoch 47/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 9.8420e-06 - val_loss: 4.4873e-06\n",
      "Epoch 48/150\n",
      "51/51 [==============================] - 1s 23ms/step - loss: 9.0716e-06 - val_loss: 1.0398e-05\n",
      "Epoch 49/150\n",
      "51/51 [==============================] - 1s 19ms/step - loss: 8.6810e-06 - val_loss: 8.6522e-06\n",
      "Epoch 50/150\n",
      "51/51 [==============================] - 1s 20ms/step - loss: 8.3465e-06 - val_loss: 1.1438e-05\n",
      "Epoch 51/150\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 7.9411e-06 - val_loss: 9.3476e-06\n",
      "Epoch 52/150\n",
      "51/51 [==============================] - 1s 18ms/step - loss: 7.3621e-06 - val_loss: 7.3254e-06\n",
      "Epoch 00052: early stopping\n",
      "INFO:tensorflow:Assets written to: ./log_dir/SAN-5/autoencoder-500/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trained model saved at: ./log_dir/SAN-5/autoencoder-500\n",
      "Training losss for layer 2: 7.018666565272724e-06 \n",
      "Testing loss for layer 2: 7.080084287736099e-06 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./log_dir/SAN-5/encoders/model_2_500/assets\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Starting training for {} encoder layers.\".format(len(config[\"N_NODES\"])))\n",
    "\n",
    "x_train_out, x_test_out = x_train, x_test\n",
    "for idx, num_hidden in enumerate(config[\"N_NODES\"]):\n",
    "    logger.info(\"Training layer {} with {} hidden nodes..\".format(idx, num_hidden))\n",
    "    encoder = Autoencoder(x_train_out.shape[1], num_hidden, os.environ['EXP_DIR'])\n",
    "    \n",
    "    recon_mse = encoder.fit(x_train_out, x_test_out, batch_size=config[\"BATCH_SIZE\"], \n",
    "        num_epochs=config[\"EPOCHS\"], verbose=config[\"VERBOSITY\"], patience=config[\"PATIENCE\"])\n",
    "    \n",
    "    x_train_out = encoder.encoder_model.predict(x_train_out)\n",
    "    x_test_out = encoder.encoder_model.predict(x_test_out)\n",
    "    logger.info(\"Training losss for layer {}: {} \".format(idx, recon_mse[0]))\n",
    "    logger.info(\"Testing loss for layer {}: {} \".format(idx, recon_mse[1]))\n",
    "    \n",
    "    model_path = os.path.join(os.environ['EXP_DIR'], \"encoders\", \"model_{}_{}\".format(idx,num_hidden))\n",
    "    encoder.encoder_model.save(model_path)\n",
    "    neptune.log_artifact(model_path)\n",
    "    neptune.set_property('encoder{}'.format(idx), model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T13:08:06.373096Z",
     "iopub.status.busy": "2020-08-07T13:08:06.372777Z",
     "iopub.status.idle": "2020-08-07T13:08:10.478314Z",
     "shell.execute_reply": "2020-08-07T13:08:10.477135Z",
     "shell.execute_reply.started": "2020-08-07T13:08:06.373063Z"
    }
   },
   "outputs": [],
   "source": [
    "neptune.stop()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "neptune": {
   "notebookId": "ecd86e96-4da7-44e3-9a17-43da2dfcae35"
  },
  "record_timing": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

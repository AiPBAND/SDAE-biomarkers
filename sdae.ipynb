{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:52:52.008081Z",
     "iopub.status.busy": "2020-08-05T20:52:52.007743Z",
     "iopub.status.idle": "2020-08-05T20:52:52.014295Z",
     "shell.execute_reply": "2020-08-05T20:52:52.013241Z",
     "shell.execute_reply.started": "2020-08-05T20:52:52.008054Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['NEPTUNE_API_TOKEN']=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiYjNiYmZhYjEtNzc3ZS00Y2NhLWI5NTgtYWU0MmQyMWJhM2I0In0=\"\n",
    "os.environ['NEPTUNE_PROJECT']=\"jgeof/sdae\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_ID']=\"ecd86e96-4da7-44e3-9a17-43da2dfcae35\"\n",
    "os.environ['NEPTUNE_NOTEBOOK_PATH']=\"constrained-SDAE/sdae.ipynb\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from models import Autoencoder, EncoderStack\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import normalize\n",
    "import dataset\n",
    "import neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:52:53.491356Z",
     "iopub.status.busy": "2020-08-05T20:52:53.490947Z",
     "iopub.status.idle": "2020-08-05T20:52:57.323002Z",
     "shell.execute_reply": "2020-08-05T20:52:57.321902Z",
     "shell.execute_reply.started": "2020-08-05T20:52:53.491326Z"
    }
   },
   "outputs": [],
   "source": [
    "!neptune tensorboard ./log_dir --project ${NEPTUNE_PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:58:07.076130Z",
     "iopub.status.busy": "2020-08-05T20:58:07.075788Z",
     "iopub.status.idle": "2020-08-05T20:57:57.815063Z",
     "shell.execute_reply": "2020-08-05T20:57:57.813618Z",
     "shell.execute_reply.started": "2020-08-05T20:57:57.809339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.2.2 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir ./log_dir --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:44:07.435301Z",
     "iopub.status.busy": "2020-08-05T20:44:07.434873Z",
     "iopub.status.idle": "2020-08-05T20:44:07.441504Z",
     "shell.execute_reply": "2020-08-05T20:44:07.440579Z",
     "shell.execute_reply.started": "2020-08-05T20:44:07.435259Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"N_NODES\": [2000, 1000, 500],\n",
    "    \"DROPOUT\": [0.1],\n",
    "    \"BATCH_SIZE\": 3,\n",
    "    \"EPOCHS\": 10,\n",
    "    \"TEST_RATIO\": 0.15,\n",
    "    \"DATA_BUCKET\": \"sdae-geo\",\n",
    "    \"DATA_OBJECT\": \"GEO_data_batch_corr_final.csv\",\n",
    "    \"DATA_LABELS\": \" GBM_class.csv\",\n",
    "    \"VERBOSITY\": 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:44:07.443738Z",
     "iopub.status.busy": "2020-08-05T20:44:07.443396Z",
     "iopub.status.idle": "2020-08-05T20:44:09.495974Z",
     "shell.execute_reply": "2020-08-05T20:44:09.494857Z",
     "shell.execute_reply.started": "2020-08-05T20:44:07.443709Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NVMLError: NVML Shared Library Not Found - GPU usage metrics may not be reported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/jgeof/sdae/e/SDAE-12\n"
     ]
    }
   ],
   "source": [
    "neptune.init(os.environ['NEPTUNE_PROJECT'], api_token=os.environ['NEPTUNE_API_TOKEN'])\n",
    "neptune.create_experiment(name='configuration', params=config)\n",
    "neptune.append_tag('minimal-example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from Google Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:44:09.497948Z",
     "iopub.status.busy": "2020-08-05T20:44:09.497505Z",
     "iopub.status.idle": "2020-08-05T20:44:13.133118Z",
     "shell.execute_reply": "2020-08-05T20:44:13.132123Z",
     "shell.execute_reply.started": "2020-08-05T20:44:09.497878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Blob GEO_data_batch_corr_final.csv downloaded to ./data/GEO_data_batch_corr_final.csv.\n",
      "Loaded 954 samples with 6785 features.\n"
     ]
    }
   ],
   "source": [
    "dataframe = dataset.load_gs_data(config['DATA_BUCKET'], config['DATA_OBJECT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data feature-wize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:44:13.138776Z",
     "iopub.status.busy": "2020-08-05T20:44:13.138394Z",
     "iopub.status.idle": "2020-08-05T20:44:13.183832Z",
     "shell.execute_reply": "2020-08-05T20:44:13.182876Z",
     "shell.execute_reply.started": "2020-08-05T20:44:13.138736Z"
    }
   },
   "outputs": [],
   "source": [
    "data = dataframe.values\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:44:13.185720Z",
     "iopub.status.busy": "2020-08-05T20:44:13.185330Z",
     "iopub.status.idle": "2020-08-05T20:44:14.083482Z",
     "shell.execute_reply": "2020-08-05T20:44:14.082440Z",
     "shell.execute_reply.started": "2020-08-05T20:44:13.185678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15% of samples for training: 810 training, 144 testing.\n"
     ]
    }
   ],
   "source": [
    "rs = ShuffleSplit(n_splits=1, test_size=config['TEST_RATIO'], random_state=0)\n",
    "split_itterator = rs.split(data)\n",
    "i_train, i_test = next(split_itterator)\n",
    "np.save(\"train_indices.npy\", i_train)\n",
    "np.save(\"test_indices.npy\", i_test)\n",
    "neptune.log_artifact('train_indices.npy')\n",
    "neptune.log_artifact('test_indices.npy')\n",
    "\n",
    "x_train, x_test = data[i_train], data[i_test]\n",
    "\n",
    "print(\"{}% of samples for training: {} training, {} testing.\".format(int(config['TEST_RATIO']*100), len(i_train), len(i_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T03:12:17.561113Z",
     "iopub.status.busy": "2020-07-27T03:12:17.560466Z",
     "iopub.status.idle": "2020-07-27T03:12:17.565053Z",
     "shell.execute_reply": "2020-07-27T03:12:17.564431Z",
     "shell.execute_reply.started": "2020-07-27T03:12:17.561079Z"
    }
   },
   "source": [
    "# Train encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-05T20:35:52.136147Z",
     "iopub.status.busy": "2020-08-05T20:35:52.135827Z",
     "iopub.status.idle": "2020-08-05T20:35:44.989424Z",
     "shell.execute_reply": "2020-08-05T20:35:44.988226Z",
     "shell.execute_reply.started": "2020-08-05T20:35:44.981214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer 0 with 2000 hidden nodes..\n",
      "\n",
      "Epoch 1/10\n",
      "318/318 [==============================] - 64s 202ms/step - loss: 0.0320 - val_loss: 1.9084e-04\n",
      "Epoch 2/10\n",
      "318/318 [==============================] - 67s 212ms/step - loss: 6.1792e-05 - val_loss: 2.1431e-05\n",
      "Epoch 3/10\n",
      "318/318 [==============================] - 63s 199ms/step - loss: 1.5967e-05 - val_loss: 9.7162e-06\n",
      "Epoch 4/10\n",
      "318/318 [==============================] - 64s 201ms/step - loss: 9.1267e-06 - val_loss: 5.9471e-06\n",
      "Epoch 5/10\n",
      " 13/318 [>.............................] - ETA: 55s - loss: 7.1620e-06"
     ]
    }
   ],
   "source": [
    "encoder_models = []\n",
    "\n",
    "x_train, x_test = data, data\n",
    "for idx, num_hidden in enumerate(config[\"N_NODES\"]):\n",
    "    print(\"Training layer {} with {} hidden nodes..\\n\".format(idx, num_hidden))\n",
    "    \n",
    "    encoder = Autoencoder(x_train.shape[1], num_hidden, \"output/\")\n",
    "    \n",
    "    recon_mse = encoder.fit(x_train, x_test, batch_size=config[\"BATCH_SIZE\"], \n",
    "        num_epochs=config[\"EPOCHS\"], verbose=config[\"VERBOSITY\"])\n",
    "    \n",
    "    x_train_out = encoder.encoder_model.predict(x_train_out)\n",
    "    x_test_out = encoder.encoder_model.predict(x_test_out)\n",
    "    print(\"\\nTraining losss: \", recon_mse[0])\n",
    "    print(\"\\nTesting loss: \", recon_mse[1])\n",
    "    encoder_models.append(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T03:19:23.111926Z",
     "iopub.status.busy": "2020-07-27T03:19:23.111222Z",
     "iopub.status.idle": "2020-07-27T03:19:26.418736Z",
     "shell.execute_reply": "2020-07-27T03:19:26.418082Z",
     "shell.execute_reply.started": "2020-07-27T03:19:23.111888Z"
    }
   },
   "source": [
    "# Train encoder stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T05:30:55.460426Z",
     "iopub.status.busy": "2020-07-27T05:30:55.459908Z",
     "iopub.status.idle": "2020-07-27T05:36:40.801916Z",
     "shell.execute_reply": "2020-07-27T05:36:40.800504Z",
     "shell.execute_reply.started": "2020-07-27T05:30:55.460372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Training layer 2 with 500 hidden nodes..\n",
      "\n",
      "Epoch 1/10\n",
      "270/270 [==============================] - 46s 172ms/step - loss: 0.0912 - val_loss: 0.0657\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 50s 184ms/step - loss: 0.0893 - val_loss: 0.0655\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 53s 195ms/step - loss: 0.0844 - val_loss: 0.0565\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 50s 184ms/step - loss: 0.0685 - val_loss: 0.0418\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 49s 183ms/step - loss: 0.0541 - val_loss: 0.0389\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 46s 170ms/step - loss: 0.0467 - val_loss: 0.0351\n",
      "Epoch 7/10\n",
      "270/270 [==============================] - 47s 173ms/step - loss: 0.0436 - val_loss: 0.0416\n",
      "Epoch 00007: early stopping\n",
      "INFO:tensorflow:Assets written to: output/20200727-053055/encoder_stack/assets\n",
      "\n",
      "Training losss:  0.27949008\n",
      "\n",
      "Testing loss:  0.2811888\n"
     ]
    }
   ],
   "source": [
    "model = EncoderStack(encoder_models, 'output/')\n",
    "\n",
    "print(\"\\n##################################################################\")\n",
    "print(\"Training layer {} with {} hidden nodes..\\n\".format(idx, num_hidden))\n",
    "loss_train, loss_test = model.fit(x_train, y_train, x_test, y_test, batch_size=BATCH_SIZE, num_epochs=EPOCHS)\n",
    "\n",
    "print(\"\\nTraining losss: \", loss_train)\n",
    "print(\"\\nTesting loss: \", loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "neptune": {
   "notebookId": "ecd86e96-4da7-44e3-9a17-43da2dfcae35"
  },
  "record_timing": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

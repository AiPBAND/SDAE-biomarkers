{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"GEO_data_batch_corr_final\"\n",
    "\n",
    "N_LAYERS = 2\n",
    "N_NODES = [100, 50]\n",
    "DROPOUT = [0.1]\n",
    "BATCH_SIZE = 10\n",
    "EPOCHS =1\n",
    "TEST_RATIO = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/20200723-233156\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output = os.path.join('output', now)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(N_NODES) == N_LAYERS or len(N_NODES) == 1\n",
    "assert len(DROPOUT) == N_LAYERS or len(DROPOUT) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(954, 6785)\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_pickle('data/pd/'+FILE_NAME)\n",
    "print(dataframe.shape)\n",
    "data = dataframe.values\n",
    "data = normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.random.randint(0,3, dataframe.shape[0])\n",
    "classes = to_categorical(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810 train samples\n",
      "144 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, classes, test_size=TEST_RATIO)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define basic two-layer autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(object):\n",
    "\n",
    "    def __init__(self, inputs, output_path, num_hidden=500, dropout_rate=0.05,\n",
    "        encoder_act='sigmoid', decoder_act='linear', bias=True, loss_fn='mse',\n",
    "        batch_size=32, num_epochs=300, optimizer='rmsprop', verbose=1):\n",
    "\n",
    "        self.inputs = inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.encoder_act = encoder_act\n",
    "        self.decoder_act = decoder_act\n",
    "        self.bias = bias\n",
    "        self.loss_fn = loss_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.optimizer = optimizer\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.num_inputs = inputs.shape[1]\n",
    "\n",
    "        now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.log = os.path.join(now, output_path)\n",
    "\n",
    "        self.tsb = TensorBoard(log_dir=self.log, write_graph=True,\n",
    "            update_freq='batch')\n",
    "\n",
    "        self.mse_obj = MeanSquaredError()\n",
    "\n",
    "        # Build layers #########################################################\n",
    "\n",
    "        dropout_layer = Dropout(rate=dropout_rate)\n",
    "        dropout_output = dropout_layer(self.inputs)\n",
    "\n",
    "        self.encoder_layer = Dense(units=self.num_hidden,\n",
    "            kernel_initializer='glorot_uniform', activation=self.encoder_act,\n",
    "            name=\"encoder{}{}\".format(self.num_inputs, self.num_hidden),\n",
    "            use_bias=self.bias)\n",
    "        self.encoder_ouput = self.encoder_layer(dropout_output)\n",
    "\n",
    "        self.decoder_layer = Dense(units=inputs.shape[1],\n",
    "            kernel_initializer='glorot_uniform', activation=self.decoder_act,\n",
    "            name=\"decdoer{}{}\".format(self.num_hidden, self.num_inputs),\n",
    "            use_bias=self.bias)\n",
    "        self.decoder_ouput = self.decoder_layer(self.encoder_ouput)\n",
    "\n",
    "        # Build model ##########################################################\n",
    "\n",
    "        self.autoencoder_model = Model(self.inputs, self.decoder_ouput)\n",
    "        self.autoencoder_model.compile(loss=self.loss_fn, optimizer=self.optimizer)\n",
    "\n",
    "        self.encoder_model = Model(self.inputs, self.encoder_ouput)\n",
    "\n",
    "    def _mse(self, real):\n",
    "        recon = self.autoencoder_model.predict(real)\n",
    "        return self.mse_obj(real, recon)\n",
    "\n",
    "    def fit_unsupervised(self, data_train, data_val, data_test):\n",
    "\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=1, verbose=0)\n",
    "\n",
    "        self.autoencoder_model.fit(x=data_train, y=data_train,\n",
    "            callbacks=[early_stop, self.tsb], epochs=self.num_epochs,\n",
    "            batch_size=self.batch_size, shuffle=True,\n",
    "            validation_data=(data_val, data_val))\n",
    "\n",
    "        self.autoencoder_model.save(os.path.join(self.log, 'model'))\n",
    "\n",
    "        return self._mse(data_train), self._mse(data_val), self._mse(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderStack(object):\n",
    "\n",
    "    def __init__(self, num_features, num_stacks=2, hidden_nodes=[500, 100], output_path=\"/\"):\n",
    "\n",
    "        assert num_stacks == len(hidden_nodes) or len(hidden_nodes) == 1\n",
    "\n",
    "        self.num_features = num_features\n",
    "        self.num_stacks = num_stacks\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_path = output_path\n",
    "\n",
    "        self.stack = []\n",
    "        self.inputs = Input(shape=(num_features,))\n",
    "\n",
    "        for i in range(self.num_stacks):\n",
    "            input_layer = self.inputs if not i else self.stack[-1].encoder_ouput\n",
    "\n",
    "            model = DenoisingAutoencoder(input_layer, output_path=self.output_path, num_hidden=hidden_nodes[i])\n",
    "\n",
    "            if i:\n",
    "                self.stack[-1].decoder_layer(model.decoder_output)\n",
    "\n",
    "            self.stack.append(model)\n",
    "\n",
    "    def unsupervised_fit(self, data_train, data_val, data_test, output_dir):\n",
    "\n",
    "        mse_per_layer = []\n",
    "\n",
    "        for layer in self.stack:\n",
    "            mse_tuple = layer.fit_unsupervised(data_train, data_val, data_test)\n",
    "            mse_per_layer.append(mse_tuple)\n",
    "\n",
    "        return mse_per_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to \"model_15\" was not an Input tensor, it was generated by layer encoder6785100.\n",
      "Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.\n",
      "The tensor that caused the issue was: encoder6785100_6/Sigmoid:0\n"
     ]
    }
   ],
   "source": [
    "model = AutoencoderStack(x_train.shape[1], num_stacks=N_LAYERS, hidden_nodes=N_NODES)\n",
    "\n",
    "encoders, data, recon_mse = model.unsupervised_fit(x_train, x_test, x_test, dir_out=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T05:11:21.643775Z",
     "iopub.status.busy": "2020-07-27T05:11:21.643500Z",
     "iopub.status.idle": "2020-07-27T05:11:24.000851Z",
     "shell.execute_reply": "2020-07-27T05:11:23.999589Z",
     "shell.execute_reply.started": "2020-07-27T05:11:21.643741Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from models import Autoencoder, EncoderStack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T05:11:24.003026Z",
     "iopub.status.busy": "2020-07-27T05:11:24.002657Z",
     "iopub.status.idle": "2020-07-27T05:11:24.009578Z",
     "shell.execute_reply": "2020-07-27T05:11:24.008423Z",
     "shell.execute_reply.started": "2020-07-27T05:11:24.002974Z"
    }
   },
   "outputs": [],
   "source": [
    "FILE_NAME = \"GEO_data_batch_corr_final\"\n",
    "FILE_CLASSES = \"GBM_class\"\n",
    "\n",
    "N_LAYERS = 3\n",
    "N_NODES = [2000, 1000, 500]\n",
    "DROPOUT = [0.1]\n",
    "BATCH_SIZE = 3\n",
    "EPOCHS = 10\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "assert len(N_NODES) == N_LAYERS or len(N_NODES) == 1\n",
    "assert len(DROPOUT) == N_LAYERS or len(DROPOUT) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T05:17:03.447681Z",
     "iopub.status.busy": "2020-07-27T05:17:03.447168Z",
     "iopub.status.idle": "2020-07-27T05:17:03.796384Z",
     "shell.execute_reply": "2020-07-27T05:17:03.794750Z",
     "shell.execute_reply.started": "2020-07-27T05:17:03.447644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 954 samples with 6785 features.\n",
      "Keeping 0.15 of samples for training: 810 training, 144 testing.\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_pickle('data/pd/'+FILE_NAME)\n",
    "print(\"Loaded {} samples with {} features.\".format(dataframe.shape[0], dataframe.shape[1]))\n",
    "data = dataframe.values\n",
    "data = normalize(data)\n",
    "\n",
    "classes = pd.read_csv('data/pd/class.csv', header=None, index_col=0).values\n",
    "classes = to_categorical(classes)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, classes, test_size=TEST_RATIO)\n",
    "print(\"Keeping {} of samples for training: {} training, {} testing.\".format(TEST_RATIO, x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T03:12:17.561113Z",
     "iopub.status.busy": "2020-07-27T03:12:17.560466Z",
     "iopub.status.idle": "2020-07-27T03:12:17.565053Z",
     "shell.execute_reply": "2020-07-27T03:12:17.564431Z",
     "shell.execute_reply.started": "2020-07-27T03:12:17.561079Z"
    }
   },
   "source": [
    "# Train encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T05:17:06.367376Z",
     "iopub.status.busy": "2020-07-27T05:17:06.366965Z",
     "iopub.status.idle": "2020-07-27T05:25:58.360978Z",
     "shell.execute_reply": "2020-07-27T05:25:58.356229Z",
     "shell.execute_reply.started": "2020-07-27T05:17:06.367343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Training layer 0 with 2000 hidden nodes..\n",
      "\n",
      "Epoch 1/10\n",
      "270/270 [==============================] - 66s 245ms/step - loss: 0.0376 - val_loss: 3.4984e-04\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 65s 241ms/step - loss: 1.0122e-04 - val_loss: 3.1444e-05\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 66s 244ms/step - loss: 2.2238e-05 - val_loss: 1.2747e-05\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 66s 246ms/step - loss: 1.1555e-05 - val_loss: 9.3970e-06\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 67s 247ms/step - loss: 8.1724e-06 - val_loss: 7.7891e-06\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 68s 251ms/step - loss: 6.2940e-06 - val_loss: 8.3466e-06\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: output/20200727-051706/autoencoder-2000/assets\n",
      "\n",
      "Training losss:  8.476895e-06\n",
      "\n",
      "Testing loss:  8.457224e-06\n",
      "\n",
      "##################################################################\n",
      "Training layer 1 with 1000 hidden nodes..\n",
      "\n",
      "Epoch 1/10\n",
      "270/270 [==============================] - 14s 51ms/step - loss: 0.0154 - val_loss: 5.9600e-04\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 14s 51ms/step - loss: 2.4908e-04 - val_loss: 5.9087e-05\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 13s 49ms/step - loss: 5.5945e-05 - val_loss: 3.0258e-05\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 12s 43ms/step - loss: 2.3990e-05 - val_loss: 1.1687e-05\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 1.4312e-05 - val_loss: 1.0579e-05\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 12s 45ms/step - loss: 9.7683e-06 - val_loss: 8.1260e-07\n",
      "Epoch 7/10\n",
      "270/270 [==============================] - 12s 44ms/step - loss: 7.2155e-06 - val_loss: 3.8198e-06\n",
      "INFO:tensorflow:Assets written to: output/20200727-052351/autoencoder-1000/assets\n",
      "\n",
      "Training losss:  3.734719e-06\n",
      "\n",
      "Testing loss:  3.747563e-06\n",
      "\n",
      "##################################################################\n",
      "Training layer 2 with 500 hidden nodes..\n",
      "\n",
      "Epoch 1/10\n",
      "270/270 [==============================] - 6s 22ms/step - loss: 0.0080 - val_loss: 0.0018\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 6s 22ms/step - loss: 0.0011 - val_loss: 3.1427e-04\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 5s 20ms/step - loss: 2.8827e-04 - val_loss: 8.5242e-05\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 6s 22ms/step - loss: 1.2129e-04 - val_loss: 5.2191e-05\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 5s 20ms/step - loss: 6.7233e-05 - val_loss: 2.5243e-05\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 5s 20ms/step - loss: 4.1056e-05 - val_loss: 4.2742e-05\n",
      "INFO:tensorflow:Assets written to: output/20200727-052522/autoencoder-500/assets\n",
      "\n",
      "Training losss:  4.3955883e-05\n",
      "\n",
      "Testing loss:  4.377273e-05\n"
     ]
    }
   ],
   "source": [
    "encoder_models = []\n",
    "\n",
    "x_train_out, x_test_out = x_train, x_test\n",
    "for idx, num_hidden in enumerate(N_NODES):\n",
    "    print(\"\\n##################################################################\")\n",
    "    print(\"Training layer {} with {} hidden nodes..\\n\".format(idx, num_hidden))\n",
    "    encoder = Autoencoder(x_train_out.shape[1], num_hidden, \"output/\")\n",
    "    recon_mse = encoder.fit(x_train_out, x_test_out, batch_size=BATCH_SIZE, num_epochs=EPOCHS)\n",
    "    x_train_out = encoder.encoder_model.predict(x_train_out)\n",
    "    x_test_out = encoder.encoder_model.predict(x_test_out)\n",
    "    print(\"\\nTraining losss: \", recon_mse[0])\n",
    "    print(\"\\nTesting loss: \", recon_mse[1])\n",
    "    encoder_models.append(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T03:19:23.111926Z",
     "iopub.status.busy": "2020-07-27T03:19:23.111222Z",
     "iopub.status.idle": "2020-07-27T03:19:26.418736Z",
     "shell.execute_reply": "2020-07-27T03:19:26.418082Z",
     "shell.execute_reply.started": "2020-07-27T03:19:23.111888Z"
    }
   },
   "source": [
    "# Train encoder stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-07-27T05:30:55.460426Z",
     "iopub.status.busy": "2020-07-27T05:30:55.459908Z",
     "iopub.status.idle": "2020-07-27T05:36:40.801916Z",
     "shell.execute_reply": "2020-07-27T05:36:40.800504Z",
     "shell.execute_reply.started": "2020-07-27T05:30:55.460372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Training layer 2 with 500 hidden nodes..\n",
      "\n",
      "Epoch 1/10\n",
      "270/270 [==============================] - 46s 172ms/step - loss: 0.0912 - val_loss: 0.0657\n",
      "Epoch 2/10\n",
      "270/270 [==============================] - 50s 184ms/step - loss: 0.0893 - val_loss: 0.0655\n",
      "Epoch 3/10\n",
      "270/270 [==============================] - 53s 195ms/step - loss: 0.0844 - val_loss: 0.0565\n",
      "Epoch 4/10\n",
      "270/270 [==============================] - 50s 184ms/step - loss: 0.0685 - val_loss: 0.0418\n",
      "Epoch 5/10\n",
      "270/270 [==============================] - 49s 183ms/step - loss: 0.0541 - val_loss: 0.0389\n",
      "Epoch 6/10\n",
      "270/270 [==============================] - 46s 170ms/step - loss: 0.0467 - val_loss: 0.0351\n",
      "Epoch 7/10\n",
      "270/270 [==============================] - 47s 173ms/step - loss: 0.0436 - val_loss: 0.0416\n",
      "Epoch 00007: early stopping\n",
      "INFO:tensorflow:Assets written to: output/20200727-053055/encoder_stack/assets\n",
      "\n",
      "Training losss:  0.27949008\n",
      "\n",
      "Testing loss:  0.2811888\n"
     ]
    }
   ],
   "source": [
    "model = EncoderStack(encoder_models, 'output/')\n",
    "\n",
    "print(\"\\n##################################################################\")\n",
    "print(\"Training layer {} with {} hidden nodes..\\n\".format(idx, num_hidden))\n",
    "loss_train, loss_test = model.fit(x_train, y_train, x_test, y_test, batch_size=BATCH_SIZE, num_epochs=EPOCHS)\n",
    "\n",
    "print(\"\\nTraining losss: \", loss_train)\n",
    "print(\"\\nTesting loss: \", loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "record_timing": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
